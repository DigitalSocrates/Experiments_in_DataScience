{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Experiments\n",
    "\n",
    "Let us peak inside a dataset and see what we find out.\n",
    "\n",
    "We will be looking for the following:\n",
    "\n",
    "1. Completeness:\n",
    "Completeness refers to how much information is available for all entities within your dataset. It assesses whether there are any missing values in your data. A higher level of completeness indicates that there are fewer missing values, ensuring that your dataset contains a comprehensive representation of the entities it describes. To evaluate completeness, you can count the number of missing values for each attribute or entity.\n",
    "\n",
    "1. Consistency:\n",
    "Consistency measures how uniform and consistent your data is throughout the dataset. It involves identifying and quantifying the number of inconsistencies or discrepancies within your data. These inconsistencies could include variations in data formats, naming conventions, or conflicting information. Maintaining data consistency is crucial for reliable analysis and reporting.\n",
    "\n",
    "1. Accuracy:\n",
    "Accuracy assesses how correct and error-free your data is. It involves identifying and counting the number of errors within your dataset. Errors could be typographical, computational, or factual inaccuracies. Accurate data is essential for making informed decisions and avoiding misleading conclusions.\n",
    "\n",
    "1. Relevancy/Auditability:\n",
    "Relevancy or auditability focuses on the presence of relevant data within your dataset. It involves evaluating the number of irrelevant values or records that do not contribute to the goals of your analysis or business needs. Ensuring that your dataset contains only pertinent information enhances its usability and effectiveness.\n",
    "\n",
    "1. Validity:\n",
    "Validity checks whether the data in your dataset adheres to predefined rules or allowable values. It involves validating data against established constraints or criteria to ensure that it meets quality standards. Valid data is trustworthy and conforms to expected norms, reducing the risk of using incorrect or invalid information.\n",
    "\n",
    "1. Uniqueness:\n",
    "Uniqueness measures how many duplicate values or records exist within your dataset. It is essential to identify and eliminate duplicates, as they can skew analysis results and waste storage resources. Maintaining data uniqueness ensures that each entity or data point is represented only once.\n",
    "\n",
    "1. Timeliness:\n",
    "Timeliness assesses how up-to-date your data is. It involves determining whether the data has been regularly updated to reflect the current state of the entities it describes. Timely data is critical for making decisions based on current information, especially in dynamic environments where data can quickly become outdated.\n",
    "\n",
    "Evaluating these data quality dimensions is essential for ensuring that your dataset is reliable, accurate, and suitable for your intended purposes. It helps in making informed decisions, conducting meaningful analyses, and maintaining data integrity over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
