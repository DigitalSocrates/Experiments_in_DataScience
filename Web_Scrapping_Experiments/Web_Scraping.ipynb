{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Scraping experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests beautifulsoup4 pandas pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore a fundamental example of web scraping by extracting lottery numbers from a lottery website and then saving this data in a Parquet file. We can use this dataset for various purposes, such as training a machine learning model to predict winning numbers.\n",
    "\n",
    "## Step 1: Web Scraping\n",
    "\n",
    "To begin, we'll utilize web scraping techniques to retrieve the latest lottery numbers from a specific lottery website. Web scraping involves extracting information from web pages programmatically. In this case, we are interested in the lottery numbers, which are typically displayed on the website.\n",
    "\n",
    "## Step 2: Data Extraction\n",
    "\n",
    "Once we've collected the lottery numbers from the website, we need to extract and structure this data. This involves parsing the HTML content of the webpage to locate the relevant information and then storing it in a structured format, such as a Python dictionary or a pandas DataFrame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy\n",
    "from src.game import Game\n",
    "from src.utils import scrape_lottery_data\n",
    "from src.utils import read_all_parquet_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare constants\n",
    "\n",
    "# extracted date format\n",
    "DATE_FORMAT = \"%a, %b %d, %Y\"\n",
    "\n",
    "# years to process\n",
    "YEARS_TO_PROCESS = [2023, 2022, 2021, 2020, 2019]\n",
    "\n",
    "# dataset filename\n",
    "DATASET_LOCAL_COPY = './static/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for all years we want to process \n",
    "for year in YEARS_TO_PROCESS:\n",
    "  # get the data for this year\n",
    "  scrape_lottery_data(year, DATASET_LOCAL_COPY, DATE_FORMAT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Ball_1 Ball_2 Ball_3 Ball_4 Ball_5 Ball_Bonus\n",
      "0  2019-12-28     20     23     39     59     60         18\n",
      "1  2019-12-25     02     04     16     30     46         20\n",
      "2  2019-12-21     19     31     35     50     67         14\n",
      "3  2019-12-18     14     18     26     39     68         09\n",
      "4  2019-12-14     03     06     12     32     64         19\n",
      "5  2019-12-11     24     29     42     44     63         10\n",
      "6  2019-12-07     18     42     53     62     66         25\n",
      "7  2019-12-04     08     27     44     51     61         14\n",
      "8  2019-11-30     15     35     42     63     68         18\n",
      "9  2019-11-27     15     26     37     53     55         21\n",
      "10 2019-11-23     28     35     38     61     66         23\n",
      "11 2019-11-20     07     15     39     40     57         12\n",
      "12 2019-11-16     14     22     26     55     63         26\n",
      "13 2019-11-13     23     26     27     28     66         11\n",
      "14 2019-11-09     14     17     35     38     60         25\n",
      "15 2019-11-06     15     28     46     62     64         17\n",
      "16 2019-11-02     03     23     32     37     58         22\n",
      "17 2019-10-30     19     22     52     56     67         21\n",
      "18 2019-10-26     03     20     48     54     59         04\n",
      "19 2019-10-23     05     12     50     61     69         23\n",
      "20 2019-10-19     14     27     29     59     65         12\n",
      "21 2019-10-16     01     05     25     63     67         03\n",
      "22 2019-10-12     12     29     34     53     65         23\n",
      "23 2019-10-09     05     18     33     43     65         02\n"
     ]
    }
   ],
   "source": [
    "# get all the files \n",
    "all_games = read_all_parquet_files(DATASET_LOCAL_COPY)\n",
    "\n",
    "if all_games is not None:\n",
    "    # Let us examine what we have\n",
    "    print(all_games.head(24))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for feature engineering if you want to play with the data in excel and whatnot \n",
    "all_games.to_csv(f'{DATASET_LOCAL_COPY}all_Games.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 599 entries, 0 to 598\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        599 non-null    datetime64[ns]\n",
      " 1   Ball_1      599 non-null    object        \n",
      " 2   Ball_2      599 non-null    object        \n",
      " 3   Ball_3      599 non-null    object        \n",
      " 4   Ball_4      599 non-null    object        \n",
      " 5   Ball_5      599 non-null    object        \n",
      " 6   Ball_Bonus  599 non-null    object        \n",
      "dtypes: datetime64[ns](1), object(6)\n",
      "memory usage: 32.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# let us \"crack\" the dataframe and see whats there\n",
    "all_games.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do not like those objects fields. \n",
    "next step to convert it to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type\n",
    "all_games['Ball_1'] = all_games['Ball_1'].astype('int32')\n",
    "all_games['Ball_2'] = all_games['Ball_2'].astype('int32')\n",
    "all_games['Ball_3'] = all_games['Ball_3'].astype('int32')\n",
    "all_games['Ball_4'] = all_games['Ball_4'].astype('int32')\n",
    "all_games['Ball_5'] = all_games['Ball_5'].astype('int32')\n",
    "all_games['Ball_Bonus'] = all_games['Ball_Bonus'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 599 entries, 0 to 598\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype         \n",
      "---  ------      --------------  -----         \n",
      " 0   Date        599 non-null    datetime64[ns]\n",
      " 1   Ball_1      599 non-null    int32         \n",
      " 2   Ball_2      599 non-null    int32         \n",
      " 3   Ball_3      599 non-null    int32         \n",
      " 4   Ball_4      599 non-null    int32         \n",
      " 5   Ball_5      599 non-null    int32         \n",
      " 6   Ball_Bonus  599 non-null    int32         \n",
      "dtypes: datetime64[ns](1), int32(6)\n",
      "memory usage: 18.8 KB\n"
     ]
    }
   ],
   "source": [
    "# so let see if it worked\n",
    "all_games.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Ball_1</th>\n",
       "      <th>Ball_2</th>\n",
       "      <th>Ball_3</th>\n",
       "      <th>Ball_4</th>\n",
       "      <th>Ball_5</th>\n",
       "      <th>Ball_Bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>599</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>599.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021-08-03 00:28:50.884807936</td>\n",
       "      <td>12.150250</td>\n",
       "      <td>23.277129</td>\n",
       "      <td>35.277129</td>\n",
       "      <td>47.193656</td>\n",
       "      <td>58.564274</td>\n",
       "      <td>13.310518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2019-01-02 00:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2020-06-08 00:00:00</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2021-10-16 00:00:00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>13.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2022-09-29 12:00:00</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2023-09-13 00:00:00</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>9.807723</td>\n",
       "      <td>11.853058</td>\n",
       "      <td>12.430543</td>\n",
       "      <td>11.949555</td>\n",
       "      <td>9.377023</td>\n",
       "      <td>7.712675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Date      Ball_1      Ball_2      Ball_3  \\\n",
       "count                            599  599.000000  599.000000  599.000000   \n",
       "mean   2021-08-03 00:28:50.884807936   12.150250   23.277129   35.277129   \n",
       "min              2019-01-02 00:00:00    1.000000    2.000000    3.000000   \n",
       "25%              2020-06-08 00:00:00    4.000000   15.000000   26.000000   \n",
       "50%              2021-10-16 00:00:00   10.000000   22.000000   36.000000   \n",
       "75%              2022-09-29 12:00:00   18.000000   31.000000   44.000000   \n",
       "max              2023-09-13 00:00:00   52.000000   58.000000   64.000000   \n",
       "std                              NaN    9.807723   11.853058   12.430543   \n",
       "\n",
       "           Ball_4      Ball_5  Ball_Bonus  \n",
       "count  599.000000  599.000000  599.000000  \n",
       "mean    47.193656   58.564274   13.310518  \n",
       "min      7.000000   22.000000    1.000000  \n",
       "25%     39.000000   54.000000    6.000000  \n",
       "50%     48.000000   61.000000   13.000000  \n",
       "75%     57.000000   66.000000   20.000000  \n",
       "max     68.000000   69.000000   26.000000  \n",
       "std     11.949555    9.377023    7.712675  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display dataframe's summary statistics including all collumns\n",
    "all_games.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm range of the downloaded data [2019, 2023]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Data Cleaning and Preprocessing\n",
    "\n",
    "Data obtained through web scraping may require cleaning and preprocessing. This can involve handling missing values, removing duplicates, and converting data types to ensure it's ready for analysis and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index\n",
    "all_games.reset_index(drop=True, inplace=True)\n",
    "all_games.set_index('Date', inplace=True)\n",
    "\n",
    "original = all_games\n",
    "\n",
    "# let us savbe it for now \n",
    "#all_games = all_games.drop('Ball_Bonus', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Data Storage\n",
    "\n",
    "Now that we have our clean and structured dataset, we'll save it in a Parquet file format. Parquet is a columnar storage format that's highly efficient for analytics and machine learning. It supports compression and works well with various data processing tools and frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store prepared dataset\n",
    "all_games.to_parquet(f'{DATASET_LOCAL_COPY}_all_games.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Exploratory Data Analysis (EDA)\n",
    "\n",
    "Before diving into model training, it's a good practice to perform exploratory data analysis. This step involves visualizing the data, calculating summary statistics, and gaining insights into the distribution and patterns of lottery numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, figsize=(15, 12))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "fig.suptitle(\"Winning numbers preserving order\", fontsize=18, y=0.95)\n",
    "\n",
    "# loop through tickers andaxes\n",
    "number_order = ['Ball_1', 'Ball_2', 'Ball_3', 'Ball_4', 'Ball_5', 'Ball_Bonus']\n",
    "for number_order, ax in zip(number_order, axs.ravel()):\n",
    "    # filter df for ticker and plot on specified axes\n",
    "    all_games[number_order].hist(ax=ax, bins=len(all_games[number_order].unique()), color='skyblue', ec='blue')\n",
    "    ax.set_title(number_order)\n",
    "    ax.set_xlabel(\"Count of \" + number_order)\n",
    "    ax.set_xlim([0, 69])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Model Development\n",
    "\n",
    "With the dataset prepared and understood, we can move on to developing a machine learning model. In this case, our goal is to predict future winning numbers based on historical data. We can use various algorithms, such as regression, time series forecasting, or neural networks, depending on the nature of the lottery game and the dataset.\n",
    "\n",
    "Note: NEXT POST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Model Evaluation and Fine-Tuning\n",
    "\n",
    "After training the model, we need to evaluate its performance using appropriate metrics. Depending on the results, we may need to fine-tune the model, adjust hyperparameters, or try different algorithms to improve its accuracy and reliability.\n",
    "\n",
    "Note: NEXT POST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Step 8: Deployment and Prediction\n",
    "\n",
    "Once we have a well-performing model, we can deploy it to make predictions on upcoming lottery draws. The model will take historical data as input and provide predictions for future winning numbers.\n",
    "\n",
    "Note: NEXT POST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Continuous Updates\n",
    "\n",
    "Lottery numbers change with each draw, so it's essential to continuously update the dataset and retrain the model to ensure its accuracy over time.\n",
    "\n",
    "In summary, web scraping, data extraction, cleaning, and model development are essential steps in creating a predictive model for lottery numbers. This process allows us to harness historical data to improve our chances of predicting winning numbers in future draws. Storing the data in a Parquet file ensures efficient data handling and analysis.\n",
    "\n",
    "Note: NEXT POST"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
